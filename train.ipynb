{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0ba994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f777b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a3e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting CUDA to load modules lazily\n",
    "# Only available on CUDA 11.7+\n",
    "# os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780a35ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 01:49:38.147342: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-04 01:49:38.467228: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-04 01:49:39.264867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-04 01:49:39.264913: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-04 01:49:39.264919: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f\"runs/unet_cotnet_{int(time.time())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f709b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from change_detection.models.layers import layers\n",
    "from change_detection.models import models\n",
    "from change_detection import dataset\n",
    "from loss.cross_entropy import EdgeCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c98f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def get_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    return info.used//1024**2\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb6746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 265 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689b4cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bab92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preparing cropped stuff for train, val, and test datasets\n",
    "ds_path = Path(\"/home/m/data/projects/dr.eftekhari - change detection/CoTNet/dataset/LEVIR-CD\").resolve()\n",
    "# dataset.make_cropped_dataset(ds_path / \"train\")\n",
    "# dataset.make_cropped_dataset(ds_path / \"val\")\n",
    "# dataset.make_cropped_dataset(ds_path / \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f19ce5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.LevirCDDataset(ds_path, limit = 48000, partition = \"train\")\n",
    "val_ds = dataset.LevirCDDataset(ds_path, limit = 20000, partition = \"val\")\n",
    "test_ds = dataset.LevirCDDataset(ds_path, partition = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32d6a5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 25088, 12544)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(test_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efef7d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 1407 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa09b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 4,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 4}\n",
    "max_epochs = 2\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, **params)\n",
    "test_loader = DataLoader(test_ds, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef7fb787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 258 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19caa3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = models.UnetCotnetNetwork(in_channels=3, classes=2)\n",
    "if not next(model.parameters()).is_cuda:\n",
    "    model.to(device)\n",
    "criterion = EdgeCrossEntropy()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bee10d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 1049 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55f7a2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18115222"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e3cee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTMinMaxScalerVectorized(object):\n",
    "    \"\"\"\n",
    "    Transforms each channel to the range [0, 1].\n",
    "    \"\"\"\n",
    "    def __call__(self, tensor):\n",
    "        scale = 1.0 / (tensor.max(dim=1, keepdim=True)[0] - tensor.min(dim=1, keepdim=True)[0]) \n",
    "        tensor.mul_(scale).sub_(tensor.min(dim=1, keepdim=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1bad23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    min_val_loss = np.inf\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "        print_gpu_utilization()\n",
    "        train_loss = 0.0\n",
    "        for imgs, labels in tqdm(train_loader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs[:, :3, :, :], imgs[:, 3:, :, :])\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # if epoch%3 == 0:\n",
    "            # validation\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        # imgs, labels = imgs.to('cpu'), labels.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(val_loader):\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(imgs[:, :3, :, :], imgs[:, 3:, :, :])\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        print('=========\\n{} Epoch {}\\nTraining loss {}\\nValidation loss {}'.format(\n",
    "        datetime.datetime.now(), epoch,\n",
    "        train_loss,\n",
    "        val_loss\n",
    "        ))\n",
    "        writer.add_scalar(\"Train loss/epoch\", train_loss / len(train_loader), epoch)\n",
    "        writer.add_scalar(\"Validation loss/epoch\", val_loss / len(val_loader), epoch)\n",
    "        writer.add_scalar(\"GPU Utilized/epoch\", get_gpu_utilization(), epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        print_gpu_utilization()\n",
    "\n",
    "        # save each epochs weights\n",
    "        if min_val_loss > val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f\"./unet_cotnet.{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcffdcb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 1049 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                    | 0/6000 [00:00<?, ?it/s]/home/m/.local/lib/python3.10/site-packages/cupy/cuda/compiler.py:464: UserWarning: cupy.cuda.compile_with_cache has been deprecated in CuPy v10, and will be removed in the future. Use cupy.RawModule or cupy.RawKernel instead.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [23:24<00:00,  4.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:35<00:00, 32.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 04:08:18.032536 Epoch 1\n",
      "Training loss 0.7547272253731887\n",
      "Validation loss 0.6542432120031848\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:54<00:00,  4.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:33<00:00, 33.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 04:32:46.475508 Epoch 2\n",
      "Training loss 0.5453564949929715\n",
      "Validation loss 0.47400997202767403\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:29<00:00,  4.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 04:56:51.465881 Epoch 3\n",
      "Training loss 0.41606950576106705\n",
      "Validation loss 0.37022064743107375\n",
      "GPU memory occupied: 2215 MB.\n",
      "GPU memory occupied: 2215 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:15<00:00,  4.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 05:20:41.677909 Epoch 4\n",
      "Training loss 0.33190409604211646\n",
      "Validation loss 0.29768188662199796\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:15<00:00,  4.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 05:44:31.589361 Epoch 5\n",
      "Training loss 0.2750035202230016\n",
      "Validation loss 0.2816027793510608\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:10<00:00,  4.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 06:08:16.510565 Epoch 6\n",
      "Training loss 0.23749750511099896\n",
      "Validation loss 0.31186165368868685\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:08<00:00,  4.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:33<00:00, 33.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 06:31:58.947659 Epoch 7\n",
      "Training loss 0.21035312778378526\n",
      "Validation loss 0.21268679572706473\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:07<00:00,  4.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:33<00:00, 33.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 06:55:39.910723 Epoch 8\n",
      "Training loss 0.19016479404767353\n",
      "Validation loss 0.24680199982284814\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:06<00:00,  4.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 07:19:20.461018 Epoch 9\n",
      "Training loss 0.1754808554239571\n",
      "Validation loss 0.20546709866576582\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:09<00:00,  4.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:33<00:00, 33.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 07:43:04.337520 Epoch 10\n",
      "Training loss 0.16280408871360122\n",
      "Validation loss 0.18563402418702918\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:08<00:00,  4.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 08:06:47.929963 Epoch 11\n",
      "Training loss 0.14814074980778\n",
      "Validation loss 0.16752284278912583\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:14<00:00,  4.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 08:30:37.382980 Epoch 12\n",
      "Training loss 0.13456365314126015\n",
      "Validation loss 0.17868275872232126\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:13<00:00,  4.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 08:54:25.652715 Epoch 13\n",
      "Training loss 0.12029791996690134\n",
      "Validation loss 0.16442937615840714\n",
      "GPU memory occupied: 2211 MB.\n",
      "GPU memory occupied: 2211 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:15<00:00,  4.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 09:18:15.819841 Epoch 14\n",
      "Training loss 0.10780536029425761\n",
      "Validation loss 0.15414327618010265\n",
      "GPU memory occupied: 2211 MB.\n",
      "GPU memory occupied: 2211 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:17<00:00,  4.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 09:42:07.804453 Epoch 15\n",
      "Training loss 0.09144187909054259\n",
      "Validation loss 0.15668059753406108\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:16<00:00,  4.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 10:05:59.449593 Epoch 16\n",
      "Training loss 0.07672284710438301\n",
      "Validation loss 0.14930702445610444\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:19<00:00,  4.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 10:29:54.204079 Epoch 17\n",
      "Training loss 0.061861344840067126\n",
      "Validation loss 0.14504715351729977\n",
      "GPU memory occupied: 2211 MB.\n",
      "GPU memory occupied: 2211 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:21<00:00,  4.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:35<00:00, 32.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 10:53:52.018496 Epoch 18\n",
      "Training loss 0.04807171837023149\n",
      "Validation loss 0.16120214928868132\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:22<00:00,  4.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:34<00:00, 33.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 11:17:49.900372 Epoch 19\n",
      "Training loss 0.030073823476520677\n",
      "Validation loss 0.13029958469536612\n",
      "GPU memory occupied: 2213 MB.\n",
      "GPU memory occupied: 2213 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:23<00:00,  4.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:35<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 11:41:49.051735 Epoch 20\n",
      "Training loss 0.014038467252627015\n",
      "Validation loss 0.13759967944660814\n",
      "GPU memory occupied: 2215 MB.\n",
      "GPU memory occupied: 2215 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [22:47<00:00,  4.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3136/3136 [01:38<00:00, 31.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "2023-07-14 12:06:15.203484 Epoch 21\n",
      "Training loss 0.00026890090915064016\n",
      "Validation loss 0.14797475552946635\n",
      "GPU memory occupied: 2243 MB.\n",
      "GPU memory occupied: 2243 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████▍                                                                                                                          | 1193/6000 [04:37<18:38,  4.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48106/4177708695.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_48106/1548906604.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, loss_fn, train_loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_loop(30, optimizer, model, criterion, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bd464be",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b0b0f",
   "metadata": {},
   "source": [
    "### Loading Model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7bd905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_outputs(x, is_label=False, figsize=(8,16)):\n",
    "    fig, axs = plt.subplots(2, x.shape[0], figsize=figsize)\n",
    "    for i in range(2):\n",
    "        for j in range(x.shape[0]):\n",
    "            if is_label:\n",
    "                axs[i, j].imshow(x[j, i, :, :].detach().cpu().numpy(), cmap=\"gray\")\n",
    "            else:\n",
    "                axs[i, j].imshow(x[j, i*3:(i+1)*3, :, :].squeeze(0).detach().cpu().numpy().transpose(1, 2, 0))\n",
    "                \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9da2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_output(model, imgs, conf = 0.3):\n",
    "    outputs = model(imgs[:, :3, :, :], imgs[:, 3:, :, :])\n",
    "    outputs = torch.nn.functional.sigmoid(outputs)\n",
    "    outputs = torch.where(outputs > conf, 1.0, 0.0)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10700dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdfd4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f31e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.UnetCotnetNetwork(in_channels=3, classes=2)\n",
    "if not next(model.parameters()).is_cuda:\n",
    "    model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "criterion = EdgeCrossEntropy()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "checkpoint = torch.load(\"./unet_cotnet.11.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "845c6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f9a448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 2783 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b6990cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                 | 0/6272 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "recall_scores, precision_scores, f1_scores = {\"0\": [], \"1\": []}, {\"0\": [], \"1\": []}, {\"0\": [], \"1\": []}\n",
    "# ---------------------\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for imgs, labels in tqdm(test_loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        preds = handle_output(model, imgs, conf=0.5)\n",
    "        for i in range(imgs.shape[0]):\n",
    "            y_pred_0 = preds[i, 0, :, :].detach().cpu().numpy().ravel().astype(np.uint8)\n",
    "            y_pred_1 = preds[i, 1, :, :].detach().cpu().numpy().ravel().astype(np.uint8) # real labels\n",
    "            y_0 = labels[i, 0, :, :].detach().cpu().numpy().ravel().astype(np.uint8)\n",
    "            y_1 = labels[i, 1, :, :].detach().cpu().numpy().ravel().astype(np.uint8) # real labels\n",
    "            \n",
    "            recall_scores[\"0\"].append(recall_score(y_pred_0, y_0, pos_label=0, average=\"binary\", zero_division=1))\n",
    "            recall_scores[\"1\"].append(recall_score(y_pred_1, y_1, pos_label=1, average=\"binary\", zero_division=1))\n",
    "            \n",
    "            precision_scores[\"0\"].append(precision_score(y_pred_0, y_0, pos_label=0, average=\"binary\", zero_division=1))\n",
    "            precision_scores[\"1\"].append(precision_score(y_pred_1, y_1, pos_label=1, average=\"binary\", zero_division=1))\n",
    "            \n",
    "            f1_scores[\"0\"].append(f1_score(y_pred_0, y_0, pos_label=0, average=\"binary\", zero_division=1))\n",
    "            f1_scores[\"1\"].append(f1_score(y_pred_1, y_1, pos_label=1, average=\"binary\", zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6282ec2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9046177464264744, 0.7461734693877551)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_scores[\"0\"]) / len(recall_scores[\"0\"]), sum(recall_scores[\"1\"]) / len(recall_scores[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b02af4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9191249035412095, 1.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(precision_scores[\"0\"]) / len(precision_scores[\"0\"]), sum(precision_scores[\"1\"]) / len(precision_scores[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9fb90c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8607025938418938, 0.7461734693877551)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f1_scores[\"0\"]) / len(f1_scores[\"0\"]), sum(f1_scores[\"1\"]) / len(f1_scores[\"1\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
